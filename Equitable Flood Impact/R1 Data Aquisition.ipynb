{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1e6b4ed-d601-4a4e-86b6-3ae5cfde328e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "osm2gmns, 0.7.5\n"
     ]
    }
   ],
   "source": [
    "from progress_utils import run_with_progress_bar  # Import the function\n",
    "import osm2gmns as og\n",
    "import osmnx as ox\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely import wkt\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "import os\n",
    "import time\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c419304-f14e-44b9-861a-8b3e3e19c9fc",
   "metadata": {},
   "source": [
    "# Getting the base dataset from osm using osm2gmns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ad3691-a943-4f7a-b19e-7bceab729b38",
   "metadata": {},
   "source": [
    "Provide the number corresponding to the location you are interested in from OpenStreetMap. Check the example screenshot [here](https://osm2gmns.readthedocs.io/en/latest/_images/osm_id.png).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a251674-eeca-4a54-9c46-8a670eab0b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.widget-label { min-width: 0 !important; } </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15c18e45b34947059326d24d9fa50f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='0% Complete | Time: 0s', layout=Layout(width='100%'), style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid reponses got from API server.\n",
      "receving data...\n",
      "map data has been written to ./data/raw_data/map.osm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3 style=\"color: green; font-weight: bold;\">✔️ Process complete!</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_osm():\n",
    "    net2 = og.downloadOSMData(179032, './data/raw_data/map.osm')\n",
    "run_with_progress_bar(get_osm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b613dec-cc4f-4aad-88ec-7d6170dbf5b7",
   "metadata": {},
   "source": [
    "Extract the necessary files from the OSM file, specifically `link.csv`, `poi.csv`, and `node.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5293837c-53ce-43d0-b66c-d948d2090468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.widget-label { min-width: 0 !important; } </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de513d74249747c1a5324929adf41844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='0% Complete | Time: 0s', layout=Layout(width='100%'), style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arguments used for network parsing:\n",
      "  filename: ./data/raw_data/map.osm\n",
      "  network_types: auto\n",
      "  link_types: all\n",
      "  POI: True\n",
      "  POI_sampling_ratio: 1.0\n",
      "  strict_mode: True\n",
      "  offset: no\n",
      "  min_nodes: 1\n",
      "  combine: False\n",
      "  bbox: None\n",
      "  default_lanes: True\n",
      "  default_speed: True\n",
      "  default_capacity: True\n",
      "  start_node_id: 0\n",
      "  start_link_id: 0\n",
      "\n",
      "Building Network from OSM file\n",
      "  reading osm file\n",
      "  parsing osm network\n",
      "    generating nodes and links\n",
      "    generating POIs\n",
      "  number of nodes: 5949, number of links: 14296, number of pois: 34402\n",
      "Generating Node Activity Information\n",
      "Outputting Network Files\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3 style=\"color: green; font-weight: bold;\">✔️ Process complete!</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_all_datasets():\n",
    "    net = og.getNetFromFile('./data/raw_data/map.osm',network_types=('auto'), POI = True, default_lanes= True, default_speed = True, default_capacity=True)\n",
    "    og.generateNodeActivityInfo(net)\n",
    "    og.connectPOIWithNet(net)\n",
    "    og.outputNetToCSV(net, './data/raw_data/')\n",
    "# Run the combined function with a single progress bar\n",
    "run_with_progress_bar(get_all_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c61e63a-63ab-4297-94d6-530e6b62076a",
   "metadata": {},
   "source": [
    "#### Loading the exported dataset for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "202ceecf-6c5e-4862-8f5f-c79aaf2ed257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " You have successfully import all the needed dataset for this steps\n"
     ]
    }
   ],
   "source": [
    "#load in the link datasets\n",
    "df = pd.read_csv('./data/raw_data/link.csv', encoding='ISO-8859-1',low_memory=False)\n",
    "\n",
    "# Step 2: Convert the 'geometry' column (containing LINESTRING in WKT format) to shapely geometries\n",
    "df['geometry'] = df['geometry'].apply(wkt.loads)\n",
    "\n",
    "# Step 3: Convert the DataFrame to a GeoDataFrame\n",
    "link_gdf = gpd.GeoDataFrame(df, geometry='geometry')\n",
    "\n",
    "# Optional: Set the Coordinate Reference System (CRS)\n",
    "link_gdf.set_crs(epsg=4326, inplace=True)  # Example for WGS84 (change EPSG code if necessary)\n",
    "\n",
    "# load the node datasets\n",
    "\n",
    "df_node = pd.read_csv('./data/raw_data/node.csv', encoding='ISO-8859-1',low_memory=False)\n",
    "df_node['activity_type'] = df_node['activity_type'].fillna('poi')\n",
    "\n",
    "# Convert the DataFrame to a GeoDataFrame\n",
    "nodes = gpd.GeoDataFrame(df_node, geometry=gpd.points_from_xy(df_node['x_coord'], df_node['y_coord']))\n",
    "\n",
    "#Set the Coordinate Reference System (CRS) for the GeoDataFrame\n",
    "nodes.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "# load the node datasets\n",
    "df_poi = pd.read_csv('./data/raw_data/poi.csv', encoding='ISO-8859-1',low_memory=False)\n",
    "\n",
    "print(' You have successfully import all the needed dataset for this steps' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3c0370-79bb-40d5-8e1e-2d48825c9bc4",
   "metadata": {},
   "source": [
    "#### Rename and Calculate for Number of lanes, Road Type, Speed limit, Travel time, and width "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d413e77e-eb27-4e6e-aa23-8ed7b836318a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have added Number of Lanes, Road type, Speed Limit, Travel time, and Road Width column to your datasets\n"
     ]
    }
   ],
   "source": [
    "# Create a copy to avoid modifying the original joined_gdf directly\n",
    "updated_gdf = link_gdf.copy()\n",
    "\n",
    "# Rename columns\n",
    "updated_gdf.rename(columns={'lanes': 'Number of Lanes', 'link_type_name': 'Road Type'}, inplace=True)\n",
    "\n",
    "# Convert free_speed from km/h to m/s for travel_time calculation (1 km/h = 1000/3600 m/s)\n",
    "updated_gdf['free_speed_m/s'] = updated_gdf['free_speed'] * (1000 / 3600)  # convert km/h to m/s\n",
    "\n",
    "# Calculate travel_time (in seconds), using length (in meters) and free_speed (in m/s)\n",
    "updated_gdf['travel_time'] = updated_gdf['length'] / updated_gdf['free_speed_m/s']\n",
    "\n",
    "# Calculate Speed Limit in mph (1 km/h = 0.621371 mph)\n",
    "updated_gdf['Speed Limit'] = updated_gdf['free_speed'] * 0.621371\n",
    "\n",
    "# Define road width based on road type\n",
    "def assign_road_width(road_type, num_lanes):\n",
    "    road_widths = {\n",
    "        'Residential': 10,\n",
    "        'Motorway': 12,\n",
    "        'Unclassified': 10,\n",
    "        'Tertiary': 10,\n",
    "        'Secondary': 11,\n",
    "        'Primary': 12,\n",
    "        'Trunk': 12,\n",
    "        'Service': 9,\n",
    "        'Living Street': 9,\n",
    "        'Track': 8,\n",
    "        'Footway': 5,\n",
    "        'Connector': 10\n",
    "    }\n",
    "    base_width = road_widths.get(road_type, 10)  # Default to 10 feet if the road type isn't found\n",
    "    return base_width * num_lanes  # Multiply by the number of lanes\n",
    "\n",
    "# Apply the road width calculation and add it as a 'width' column\n",
    "updated_gdf['width'] = updated_gdf.apply(lambda row: assign_road_width(row['Road Type'], row['Number of Lanes']), axis=1)\n",
    "\n",
    "# Remove the 'free_speed_m/s' column since it's only for calculation purposes\n",
    "updated_gdf.drop(columns=['free_speed_m/s'], inplace=True)\n",
    "\n",
    "print('You have added Number of Lanes, Road type, Speed Limit, Travel time, and Road Width column to your datasets')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69b7fa3-df5c-46ec-945f-873b2dfd45d0",
   "metadata": {},
   "source": [
    "#### Calculate the The Grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80b94dac-b0fe-4fde-b36e-84c31724572a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We now have the elevation information for our datasets\n"
     ]
    }
   ],
   "source": [
    "# Load DEM (assuming you have a raster file containing elevation data)\n",
    "dem_path = \"./data/raw_data/Wilmington, NC_Copernicus_DSM_COG_10_N34_00_W078_00_HAND.tif\"\n",
    "dem = rasterio.open(dem_path)\n",
    "\n",
    "# Function to extract elevation using rasterio\n",
    "def extract_elevation(geometry, dem):\n",
    "    coords = [(geometry.x, geometry.y)]\n",
    "    for val in dem.sample(coords):\n",
    "        return val[0]\n",
    "\n",
    "# Function to calculate the grade\n",
    "def calculate_grade(row, node_gdf):\n",
    "    # Skip calculation for \"Connector\" road types\n",
    "    if row['Road Type'] == 'Connector':\n",
    "        return np.nan, np.nan\n",
    "    \n",
    "    # Extract node information using 'from_node_id' and 'to_node_id'\n",
    "    start_node_elev = node_gdf.loc[node_gdf['node_id'] == row['from_node_id'], 'elevation'].values[0]\n",
    "    end_node_elev = node_gdf.loc[node_gdf['node_id'] == row['to_node_id'], 'elevation'].values[0]\n",
    "    \n",
    "    # Calculate the elevation difference and horizontal distance (length)\n",
    "    elevation_diff = end_node_elev - start_node_elev\n",
    "    distance = row['length']\n",
    "    \n",
    "    # Calculate grade (elevation difference divided by length)\n",
    "    if distance == 0:\n",
    "        return np.nan, np.nan  # Avoid division by zero\n",
    "    grade = elevation_diff / distance\n",
    "    grade_abs = abs(grade)\n",
    "    \n",
    "    return grade, grade_abs\n",
    "\n",
    "# Extract elevation for each point in nodes GeoDataFrame\n",
    "nodes['elevation'] = nodes['geometry'].apply(lambda geom: extract_elevation(geom, dem))\n",
    "\n",
    "# Calculate grade and grade_abs for updated_gdf (skipping 'Connector' road types)\n",
    "updated_gdf['grade'], updated_gdf['grade_abs'] = zip(*updated_gdf.apply(calculate_grade, axis=1, node_gdf=nodes))\n",
    "\n",
    "# Remove elevation calculation for activity_type = 'poi'\n",
    "nodes.loc[nodes['activity_type'] == 'poi', 'elevation'] = np.nan\n",
    "\n",
    "print('We now have the elevation information for our datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee2858c-2b19-4719-b39b-b29b2a01e1fd",
   "metadata": {},
   "source": [
    "#### Getting the elevation for the links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4e58462-7138-42f1-9f77-f2898a3ff7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elevation columns have been successfully added to the links file.\n"
     ]
    }
   ],
   "source": [
    "links = updated_gdf.copy()\n",
    "\n",
    "# Ensure 'node_id' and 'elevation' columns exist in the nodes file\n",
    "if 'node_id' not in nodes.columns or 'elevation' not in nodes.columns:\n",
    "    raise ValueError(\"The nodes file must contain 'node_id' and 'elevation' columns.\")\n",
    "\n",
    "# Ensure 'from_node_id' and 'to_node_id' exist in the links file\n",
    "if 'from_node_id' not in links.columns or 'to_node_id' not in links.columns:\n",
    "    raise ValueError(\"The links file must contain 'from_node_id' and 'to_node_id' columns.\")\n",
    "\n",
    "# Create a mapping from node_id to elevation\n",
    "node_elevation_map = dict(zip(nodes['node_id'], nodes['elevation']))\n",
    "\n",
    "# Add elevation_from and elevation_to columns to the links file\n",
    "def get_elevation(node_id):\n",
    "    return node_elevation_map.get(node_id, None)\n",
    "\n",
    "links['elevation_from'] = links['from_node_id'].map(get_elevation)\n",
    "links['elevation_to'] = links['to_node_id'].map(get_elevation)\n",
    "\n",
    "# Set elevation_to and elevation_from to null for connectors\n",
    "links.loc[links['Road Type'] == 'Connector', ['elevation_from', 'elevation_to']] = None\n",
    "\n",
    "print(\"Elevation columns have been successfully added to the links file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f45fdc3-f10c-4969-8cfd-82ab963ec926",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes.to_csv('./data/node.csv', index=False)\n",
    "links.to_csv('./data/link.csv', index=False)\n",
    "df_poi.to_csv('./data/poi.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a17e5b-418b-45c0-8948-a23ac0c0d607",
   "metadata": {},
   "source": [
    "### Rencode to UTF-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7cc3f59-2194-4e18-99b8-1b84748bc865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'poi.csv' successfully converted to UTF-8.\n",
      "File 'node.csv' successfully converted to UTF-8.\n",
      "File 'link.csv' successfully converted to UTF-8.\n"
     ]
    }
   ],
   "source": [
    "def convert_to_utf8(input_dir, file_name):\n",
    "    input_file = os.path.join(input_dir, file_name)\n",
    "    \n",
    "    try:\n",
    "        # Read the file with the current encoding (ISO-8859-1 or Windows-1252, etc.)\n",
    "        with open(input_file, 'r', encoding='ISO-8859-1') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # Write the content back to the original file in UTF-8 encoding\n",
    "        with open(input_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(content)\n",
    "        \n",
    "        print(f\"File '{file_name}' successfully converted to UTF-8.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to convert file '{file_name}': {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_dir = './data'\n",
    "    \n",
    "    # List of files to convert\n",
    "    files_to_convert = ['poi.csv', 'node.csv', 'link.csv']\n",
    "    \n",
    "    # Loop over the files and convert each one\n",
    "    for file_name in files_to_convert:\n",
    "        convert_to_utf8(input_dir, file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39443d7-ca03-41d6-b521-f3628f43dca8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (geo)",
   "language": "python",
   "name": "geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
