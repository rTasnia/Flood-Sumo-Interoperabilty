{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1e6b4ed-d601-4a4e-86b6-3ae5cfde328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from progress_utils import run_with_progress_bar  # Import the function\n",
    "import osm2gmns as og\n",
    "import osmnx as ox\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely import wkt\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "import os\n",
    "import time\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c419304-f14e-44b9-861a-8b3e3e19c9fc",
   "metadata": {},
   "source": [
    "# Getting the base dataset from osm using osm2gmns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ad3691-a943-4f7a-b19e-7bceab729b38",
   "metadata": {},
   "source": [
    "Provide the number corresponding to the location you are interested in from OpenStreetMap. Check the example screenshot [here](https://osm2gmns.readthedocs.io/en/latest/_images/osm_id.png).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a251674-eeca-4a54-9c46-8a670eab0b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.widget-label { min-width: 0 !important; } </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "210654700a534fceb1be7a2fde9b6a9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='0% Complete | Time: 0s', layout=Layout(width='100%'), style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid reponses got from API server.\n",
      "receving data...\n",
      "map data has been written to ./data/raw_data/map.osm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3 style=\"color: green; font-weight: bold;\">✔️ Process complete!</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_osm():\n",
    "    net2 = og.downloadOSMData(1236353, './data/raw_data/map.osm')\n",
    "run_with_progress_bar(get_osm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b613dec-cc4f-4aad-88ec-7d6170dbf5b7",
   "metadata": {},
   "source": [
    "Extract the necessary files from the OSM file, specifically `link.csv`, `poi.csv`, and `node.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5293837c-53ce-43d0-b66c-d948d2090468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.widget-label { min-width: 0 !important; } </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c4bc7c068347e08500f935da1a7205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='0% Complete | Time: 0s', layout=Layout(width='100%'), style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arguments used for network parsing:\n",
      "  filename: ./data/raw_data/map.osm\n",
      "  network_types: auto\n",
      "  link_types: all\n",
      "  POI: True\n",
      "  POI_sampling_ratio: 1.0\n",
      "  strict_mode: True\n",
      "  offset: no\n",
      "  min_nodes: 1\n",
      "  combine: False\n",
      "  bbox: None\n",
      "  default_lanes: True\n",
      "  default_speed: True\n",
      "  default_capacity: True\n",
      "  start_node_id: 0\n",
      "  start_link_id: 0\n",
      "\n",
      "Building Network from OSM file\n",
      "  reading osm file\n",
      "  parsing osm network\n",
      "    generating nodes and links\n",
      "    generating POIs\n",
      "  number of nodes: 863, number of links: 1869, number of pois: 1687\n",
      "Generating Node Activity Information\n",
      "Outputting Network Files\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3 style=\"color: green; font-weight: bold;\">✔️ Process complete!</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_all_datasets():\n",
    "    net = og.getNetFromFile('./data/raw_data/map.osm',network_types=('auto'), POI = True, default_lanes= True, default_speed = True, default_capacity=True)\n",
    "    og.generateNodeActivityInfo(net)\n",
    "    og.connectPOIWithNet(net)\n",
    "    og.outputNetToCSV(net, './data/raw_data/')\n",
    "# Run the combined function with a single progress bar\n",
    "run_with_progress_bar(get_all_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab9d5152-0df7-4d25-abdf-c49934543428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\data\\raw_data\\node.csv updated successfully.\n",
      ".\\data\\raw_data\\link.csv updated successfully.\n",
      ".\\data\\raw_data\\poi.csv updated successfully.\n"
     ]
    }
   ],
   "source": [
    "#custom code to increase IDs by 1\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define file paths\n",
    "data_folder = r\".\\data\\raw_data\"\n",
    "node_file = os.path.join(data_folder, \"node.csv\")\n",
    "links_file = os.path.join(data_folder, \"link.csv\")\n",
    "poi_file = os.path.join(data_folder, \"poi.csv\")\n",
    "\n",
    "# Update node.csv\n",
    "node_df = pd.read_csv(node_file)\n",
    "if 'node_id' in node_df.columns:\n",
    "    node_df['node_id'] += 1\n",
    "    node_df.to_csv(node_file, index=False)  # Overwrite the old file\n",
    "    print(f\"{node_file} updated successfully.\")\n",
    "else:\n",
    "    print(f\"'node_id' column not found in {node_file}.\")\n",
    "\n",
    "# Update links.csv\n",
    "links_df = pd.read_csv(links_file)\n",
    "for col in ['link_id', 'from_node_id', 'to_node_id']:\n",
    "    if col in links_df.columns:\n",
    "        links_df[col] += 1\n",
    "    else:\n",
    "        print(f\"'{col}' column not found in {links_file}.\")\n",
    "links_df.to_csv(links_file, index=False)  # Overwrite the old file\n",
    "print(f\"{links_file} updated successfully.\")\n",
    "\n",
    "# Update poi.csv\n",
    "poi_df = pd.read_csv(poi_file)\n",
    "if 'poi_id' in poi_df.columns:\n",
    "    poi_df['poi_id'] += 1\n",
    "    poi_df.to_csv(poi_file, index=False)  # Overwrite the old file\n",
    "    print(f\"{poi_file} updated successfully.\")\n",
    "else:\n",
    "    print(f\"'poi_id' column not found in {poi_file}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c61e63a-63ab-4297-94d6-530e6b62076a",
   "metadata": {},
   "source": [
    "#### Loading the exported dataset for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "202ceecf-6c5e-4862-8f5f-c79aaf2ed257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " You have successfully import all the needed dataset for this steps\n"
     ]
    }
   ],
   "source": [
    "#load in the link datasets\n",
    "df = pd.read_csv('./data/raw_data/link.csv', encoding='ISO-8859-1',low_memory=False)\n",
    "\n",
    "# Step 2: Convert the 'geometry' column (containing LINESTRING in WKT format) to shapely geometries\n",
    "df['geometry'] = df['geometry'].apply(wkt.loads)\n",
    "\n",
    "# Step 3: Convert the DataFrame to a GeoDataFrame\n",
    "link_gdf = gpd.GeoDataFrame(df, geometry='geometry')\n",
    "\n",
    "# Optional: Set the Coordinate Reference System (CRS)\n",
    "link_gdf.set_crs(epsg=4326, inplace=True)  # Example for WGS84 (change EPSG code if necessary)\n",
    "\n",
    "# load the node datasets\n",
    "\n",
    "df_node = pd.read_csv('./data/raw_data/node.csv', encoding='ISO-8859-1',low_memory=False)\n",
    "df_node['activity_type'] = df_node['activity_type'].fillna('poi')\n",
    "\n",
    "# Convert the DataFrame to a GeoDataFrame\n",
    "nodes = gpd.GeoDataFrame(df_node, geometry=gpd.points_from_xy(df_node['x_coord'], df_node['y_coord']))\n",
    "\n",
    "#Set the Coordinate Reference System (CRS) for the GeoDataFrame\n",
    "nodes.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "# load the node datasets\n",
    "df_poi = pd.read_csv('./data/raw_data/poi.csv', encoding='ISO-8859-1',low_memory=False)\n",
    "\n",
    "print(' You have successfully import all the needed dataset for this steps' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3c0370-79bb-40d5-8e1e-2d48825c9bc4",
   "metadata": {},
   "source": [
    "#### Rename and Calculate for Number of lanes, Road Type, Speed limit, Travel time, and width "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d413e77e-eb27-4e6e-aa23-8ed7b836318a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have added Number of Lanes, Road type, Speed Limit, Travel time, and Road Width column to your datasets\n"
     ]
    }
   ],
   "source": [
    "# Create a copy to avoid modifying the original joined_gdf directly\n",
    "updated_gdf = link_gdf.copy()\n",
    "\n",
    "# Rename columns\n",
    "updated_gdf.rename(columns={'lanes': 'Number of Lanes', 'link_type_name': 'Road Type'}, inplace=True)\n",
    "\n",
    "# Convert free_speed from km/h to m/s for travel_time calculation (1 km/h = 1000/3600 m/s)\n",
    "updated_gdf['free_speed_m/s'] = updated_gdf['free_speed'] * (1000 / 3600)  # convert km/h to m/s\n",
    "\n",
    "# Calculate travel_time (in seconds), using length (in meters) and free_speed (in m/s)\n",
    "updated_gdf['travel_time'] = updated_gdf['length'] / updated_gdf['free_speed_m/s']\n",
    "\n",
    "# Calculate Speed Limit in mph (1 km/h = 0.621371 mph)\n",
    "updated_gdf['Speed Limit'] = updated_gdf['free_speed'] * 0.621371\n",
    "\n",
    "# Define road width based on road type\n",
    "def assign_road_width(road_type, num_lanes):\n",
    "    road_widths = {\n",
    "        'Residential': 10,\n",
    "        'Motorway': 12,\n",
    "        'Unclassified': 10,\n",
    "        'Tertiary': 10,\n",
    "        'Secondary': 11,\n",
    "        'Primary': 12,\n",
    "        'Trunk': 12,\n",
    "        'Service': 9,\n",
    "        'Living Street': 9,\n",
    "        'Track': 8,\n",
    "        'Footway': 5,\n",
    "        'Connector': 10\n",
    "    }\n",
    "    base_width = road_widths.get(road_type, 10)  # Default to 10 feet if the road type isn't found\n",
    "    return base_width * num_lanes  # Multiply by the number of lanes\n",
    "\n",
    "# Apply the road width calculation and add it as a 'width' column\n",
    "updated_gdf['width'] = updated_gdf.apply(lambda row: assign_road_width(row['Road Type'], row['Number of Lanes']), axis=1)\n",
    "\n",
    "# Remove the 'free_speed_m/s' column since it's only for calculation purposes\n",
    "updated_gdf.drop(columns=['free_speed_m/s'], inplace=True)\n",
    "\n",
    "print('You have added Number of Lanes, Road type, Speed Limit, Travel time, and Road Width column to your datasets')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69b7fa3-df5c-46ec-945f-873b2dfd45d0",
   "metadata": {},
   "source": [
    "#### Calculate the The Grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80b94dac-b0fe-4fde-b36e-84c31724572a",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m nodes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124melevation\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m nodes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m geom: extract_elevation(geom, dem))\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Calculate grade and grade_abs for updated_gdf (skipping 'Connector' road types)\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m updated_gdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrade\u001b[39m\u001b[38;5;124m'\u001b[39m], updated_gdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrade_abs\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[43mupdated_gdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcalculate_grade\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_gdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Remove elevation calculation for activity_type = 'poi'\u001b[39;00m\n\u001b[0;32m     40\u001b[0m nodes\u001b[38;5;241m.\u001b[39mloc[nodes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivity_type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoi\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124melevation\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\geopandas\\geodataframe.py:1571\u001b[0m, in \u001b[0;36mGeoDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   1569\u001b[0m \u001b[38;5;129m@doc\u001b[39m(pd\u001b[38;5;241m.\u001b[39mDataFrame)\n\u001b[0;32m   1570\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, raw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, result_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, args\u001b[38;5;241m=\u001b[39m(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 1571\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m   1573\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1574\u001b[0m     \u001b[38;5;66;03m# pandas <1.4 re-attach last geometry col if lost\u001b[39;00m\n\u001b[0;32m   1575\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1576\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m compat\u001b[38;5;241m.\u001b[39mPANDAS_GE_14\n\u001b[0;32m   1577\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, GeoDataFrame)\n\u001b[0;32m   1578\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_geometry_column_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1579\u001b[0m     ):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m  10373\u001b[0m )\n\u001b[1;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[1;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[31], line 18\u001b[0m, in \u001b[0;36mcalculate_grade\u001b[1;34m(row, node_gdf)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan, np\u001b[38;5;241m.\u001b[39mnan\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Extract node information using 'from_node_id' and 'to_node_id'\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m start_node_elev \u001b[38;5;241m=\u001b[39m \u001b[43mnode_gdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnode_gdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnode_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfrom_node_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43melevation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     19\u001b[0m end_node_elev \u001b[38;5;241m=\u001b[39m node_gdf\u001b[38;5;241m.\u001b[39mloc[node_gdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnode_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto_node_id\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124melevation\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Calculate the elevation difference and horizontal distance (length)\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "# Load DEM (assuming you have a raster file containing elevation data)\n",
    "dem_path = \"./data/raw_data/Hyde county.tif\"\n",
    "dem = rasterio.open(dem_path)\n",
    "\n",
    "# Function to extract elevation using rasterio\n",
    "def extract_elevation(geometry, dem):\n",
    "    coords = [(geometry.x, geometry.y)]\n",
    "    for val in dem.sample(coords):\n",
    "        return val[0]\n",
    "\n",
    "# Function to calculate the grade\n",
    "def calculate_grade(row, node_gdf):\n",
    "    # Skip calculation for \"Connector\" road types\n",
    "    if row['Road Type'] == 'Connector':\n",
    "        return np.nan, np.nan\n",
    "    \n",
    "    # Extract node information using 'from_node_id' and 'to_node_id'\n",
    "    start_node_elev = node_gdf.loc[node_gdf['node_id'] == row['from_node_id'], 'elevation'].values[0]\n",
    "    end_node_elev = node_gdf.loc[node_gdf['node_id'] == row['to_node_id'], 'elevation'].values[0]\n",
    "    \n",
    "    # Calculate the elevation difference and horizontal distance (length)\n",
    "    elevation_diff = end_node_elev - start_node_elev\n",
    "    distance = row['length']\n",
    "    \n",
    "    # Calculate grade (elevation difference divided by length)\n",
    "    if distance == 0:\n",
    "        return np.nan, np.nan  # Avoid division by zero\n",
    "    grade = elevation_diff / distance\n",
    "    grade_abs = abs(grade)\n",
    "    \n",
    "    return grade, grade_abs\n",
    "\n",
    "# Extract elevation for each point in nodes GeoDataFrame\n",
    "nodes['elevation'] = nodes['geometry'].apply(lambda geom: extract_elevation(geom, dem))\n",
    "\n",
    "# Calculate grade and grade_abs for updated_gdf (skipping 'Connector' road types)\n",
    "updated_gdf['grade'], updated_gdf['grade_abs'] = zip(*updated_gdf.apply(calculate_grade, axis=1, node_gdf=nodes))\n",
    "\n",
    "# Remove elevation calculation for activity_type = 'poi'\n",
    "nodes.loc[nodes['activity_type'] == 'poi', 'elevation'] = np.nan\n",
    "\n",
    "print('We now have the elevation information for our datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee2858c-2b19-4719-b39b-b29b2a01e1fd",
   "metadata": {},
   "source": [
    "#### Getting the elevation for the links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4e58462-7138-42f1-9f77-f2898a3ff7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elevation columns have been successfully added to the links file.\n"
     ]
    }
   ],
   "source": [
    "links = updated_gdf.copy()\n",
    "\n",
    "# Ensure 'node_id' and 'elevation' columns exist in the nodes file\n",
    "if 'node_id' not in nodes.columns or 'elevation' not in nodes.columns:\n",
    "    raise ValueError(\"The nodes file must contain 'node_id' and 'elevation' columns.\")\n",
    "\n",
    "# Ensure 'from_node_id' and 'to_node_id' exist in the links file\n",
    "if 'from_node_id' not in links.columns or 'to_node_id' not in links.columns:\n",
    "    raise ValueError(\"The links file must contain 'from_node_id' and 'to_node_id' columns.\")\n",
    "\n",
    "# Create a mapping from node_id to elevation\n",
    "node_elevation_map = dict(zip(nodes['node_id'], nodes['elevation']))\n",
    "\n",
    "# Add elevation_from and elevation_to columns to the links file\n",
    "def get_elevation(node_id):\n",
    "    return node_elevation_map.get(node_id, None)\n",
    "\n",
    "links['elevation_from'] = links['from_node_id'].map(get_elevation)\n",
    "links['elevation_to'] = links['to_node_id'].map(get_elevation)\n",
    "\n",
    "# Set elevation_to and elevation_from to null for connectors\n",
    "links.loc[links['Road Type'] == 'Connector', ['elevation_from', 'elevation_to']] = None\n",
    "\n",
    "print(\"Elevation columns have been successfully added to the links file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5f45fdc3-f10c-4969-8cfd-82ab963ec926",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes.to_csv('./data/node.csv', index=False)\n",
    "links.to_csv('./data/link.csv', index=False)\n",
    "df_poi.to_csv('./data/poi.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a17e5b-418b-45c0-8948-a23ac0c0d607",
   "metadata": {},
   "source": [
    "### Rencode to UTF-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7cc3f59-2194-4e18-99b8-1b84748bc865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'poi.csv' successfully converted to UTF-8.\n",
      "File 'node.csv' successfully converted to UTF-8.\n",
      "File 'link.csv' successfully converted to UTF-8.\n"
     ]
    }
   ],
   "source": [
    "def convert_to_utf8(input_dir, file_name):\n",
    "    input_file = os.path.join(input_dir, file_name)\n",
    "    \n",
    "    try:\n",
    "        # Read the file with the current encoding (ISO-8859-1 or Windows-1252, etc.)\n",
    "        with open(input_file, 'r', encoding='ISO-8859-1') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # Write the content back to the original file in UTF-8 encoding\n",
    "        with open(input_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(content)\n",
    "        \n",
    "        print(f\"File '{file_name}' successfully converted to UTF-8.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to convert file '{file_name}': {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_dir = './data'\n",
    "    \n",
    "    # List of files to convert\n",
    "    files_to_convert = ['poi.csv', 'node.csv', 'link.csv']\n",
    "    \n",
    "    # Loop over the files and convert each one\n",
    "    for file_name in files_to_convert:\n",
    "        convert_to_utf8(input_dir, file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39443d7-ca03-41d6-b521-f3628f43dca8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
