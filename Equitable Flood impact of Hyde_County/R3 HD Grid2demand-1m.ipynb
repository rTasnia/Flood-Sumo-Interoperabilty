{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b6adaaa-232d-48f0-90bd-b321e6212df3",
   "metadata": {},
   "source": [
    "### Calculating the Demand using Grid2demand Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9b41264-e8bd-410a-ace6-c908d1235599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from grid2demand import GRID2DEMAND\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "from shapely.geometry import Point, LineString\n",
    "import geopandas as gpd\n",
    "import os\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01cbc2f-221d-41c2-8def-db5f5a0e8c67",
   "metadata": {},
   "source": [
    "### Calculate Demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f253523-dc2c-4405-9854-c3c318f550e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  : Checking input directory...\n",
      "  : input dir ./data/1m, traverse files by type: csv\n",
      "  : Optional files: ['zone.csv'] are found in ./data/1m.\n",
      "  : Optional files could be used in the following steps.\n",
      "  : Input directory is valid.\n",
      "\n",
      "  : Loading default package settings...\n",
      "  : Package settings loaded successfully.\n",
      "\n",
      "INFO Begin to run function: read_network …\n",
      "  : input dir ./data/1m, traverse files by type: csv\n",
      "INFO Begin to run function: read_node …\n",
      "  : Parallel creating Nodes using Pool with 12 CPUs. Please wait...\n",
      "  : Reading node.csv with specified columns: ['node_id', 'x_coord', 'y_coord', 'activity_type', 'is_boundary', 'poi_id']                 \n",
      "    and chunksize 10000 for iterations...\n",
      "  : Successfully loaded node.csv: 2550 Nodes loaded.\n",
      "INFO Finished running function: read_node, total: 1s\n",
      "\n",
      "INFO Begin to run function: read_poi …\n",
      "  : Reading poi.csv with specified columns: ['poi_id', 'building', 'centroid', 'area', 'geometry']                 \n",
      "    and chunksize 10000 for iterations...\n",
      "  : Parallel creating POIs using Pool with 12 CPUs. Please wait...\n",
      "  : Successfully loaded poi.csv: 1687 POIs loaded.\n",
      "INFO Finished running function: read_poi, total: 1s\n",
      "\n",
      "  : Successfully loaded node.csv and poi.csv: 2550 Nodes and 1687 POIs.\n",
      "INFO Finished running function: read_network, total: 2s\n",
      "\n",
      "  : Note: This method will generate grid-based zones from node_dict.               \n",
      "  : If you want to use your own zones(TAZs),               \n",
      "  : please skip this method and use taz2zone() instead. \n",
      "\n",
      "  : Generating zone dictionary...\n",
      "INFO Begin to run function: net2zone …\n",
      "INFO Begin to run function: get_lng_lat_min_max …\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m gd \u001b[38;5;241m=\u001b[39m GRID2DEMAND(input_dir)\n\u001b[0;32m      4\u001b[0m node_dict, poi_dict \u001b[38;5;241m=\u001b[39m gd\u001b[38;5;241m.\u001b[39mload_network\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[1;32m----> 6\u001b[0m zone_dict \u001b[38;5;241m=\u001b[39m \u001b[43mgd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet2zone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_x_blocks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mnum_y_blocks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Generate zone based on grid size with 10 km width and 10km height for each zone\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# zone_dict = gd.net2zone(node_dict, cell_width=10, cell_height=10, unit=\"km\")\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#       add zone_id to node and poi dictionaries\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#       also add node_list and poi_list to zone dictionary\u001b[39;00m\n\u001b[0;32m     18\u001b[0m updated_dict \u001b[38;5;241m=\u001b[39m gd\u001b[38;5;241m.\u001b[39msync_geometry_between_zone_and_node_poi(zone_dict, node_dict, poi_dict)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\grid2demand\\_grid2demand.py:175\u001b[0m, in \u001b[0;36mGRID2DEMAND.net2zone\u001b[1;34m(self, node_dict, num_x_blocks, num_y_blocks, cell_width, cell_height, unit)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  : Note: This method will generate grid-based zones from node_dict. \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;124m      \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  : If you want to use your own zones(TAZs), \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;124m      \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  : please skip this method and use taz2zone() instead. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  : Generating zone dictionary...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 175\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzone_dict \u001b[38;5;241m=\u001b[39m \u001b[43mnet2zone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_x_blocks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_y_blocks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzone_dict\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\grid2demand\\utils_lib\\utils.py:137\u001b[0m, in \u001b[0;36mfunc_running_time.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mINFO Begin to run function: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m …\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    136\u001b[0m time_start \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m--> 137\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m time_diff \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow() \u001b[38;5;241m-\u001b[39m time_start\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mINFO Finished running function: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, total: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime_diff\u001b[38;5;241m.\u001b[39mseconds\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\grid2demand\\func_lib\\gen_zone.py:90\u001b[0m, in \u001b[0;36mnet2zone\u001b[1;34m(node_dict, num_x_blocks, num_y_blocks, cell_width, cell_height, unit)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"convert node_dict to zone_dict by grid.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03mThe grid can be defined by num_x_blocks and num_y_blocks, or cell_width and cell_height.\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;124;03mif num_x_blocks and num_y_blocks are specified, the grid will be divided into num_x_blocks * num_y_blocks.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     79\u001b[0m \n\u001b[0;32m     80\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# # convert node_dict to dataframe\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# df_node = pd.DataFrame(node_dict.values())\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# # get the boundary of the study area\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# coord_y_min, coord_y_max = df_node['y_coord'].min(\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# ) - 0.000001, df_node['y_coord'].max() + 0.000001\u001b[39;00m\n\u001b[1;32m---> 90\u001b[0m coord_x_min, coord_x_max, coord_y_min, coord_y_max \u001b[38;5;241m=\u001b[39m \u001b[43mget_lng_lat_min_max\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# Priority: num_x_blocks, number_y_blocks > cell_width, cell_height\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# if num_x_blocks and num_y_blocks are given, use them to partition the study area\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# else if cell_width and cell_height are given, use them to partition the study area\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# else raise error\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_x_blocks \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m num_y_blocks \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\grid2demand\\utils_lib\\utils.py:137\u001b[0m, in \u001b[0;36mfunc_running_time.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mINFO Begin to run function: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m …\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    136\u001b[0m time_start \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m--> 137\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m time_diff \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow() \u001b[38;5;241m-\u001b[39m time_start\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mINFO Finished running function: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, total: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime_diff\u001b[38;5;241m.\u001b[39mseconds\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\grid2demand\\func_lib\\gen_zone.py:31\u001b[0m, in \u001b[0;36mget_lng_lat_min_max\u001b[1;34m(node_dict)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;129m@func_running_time\u001b[39m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_lng_lat_min_max\u001b[39m(node_dict: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mint\u001b[39m, Node]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m     23\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the boundary of the study area\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;03m        list: [min_lng, max_lng, min_lat, max_lat]\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m     coord_x_min, coord_x_max \u001b[38;5;241m=\u001b[39m \u001b[43mnode_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mx_coord, node_dict[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mx_coord\n\u001b[0;32m     32\u001b[0m     coord_y_min, coord_y_max \u001b[38;5;241m=\u001b[39m node_dict[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39my_coord, node_dict[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39my_coord\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m node_id \u001b[38;5;129;01min\u001b[39;00m node_dict:\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "input_dir = \"./data/1m\"\n",
    "gd = GRID2DEMAND(input_dir)\n",
    "\n",
    "node_dict, poi_dict = gd.load_network.values()\n",
    "\n",
    "zone_dict = gd.net2zone(node_dict, num_x_blocks=20,num_y_blocks=20)\n",
    "\n",
    "# Generate zone based on grid size with 10 km width and 10km height for each zone\n",
    "# zone_dict = gd.net2zone(node_dict, cell_width=10, cell_height=10, unit=\"km\")\n",
    "\n",
    "# if you have your own zone.csv(TAZs), we can generate zones from your personal TAZs\n",
    "# zone_dict = gd.taz2zone()\n",
    "\n",
    "\n",
    "# Synchronize geometry info between zone, node and poi\n",
    "#       add zone_id to node and poi dictionaries\n",
    "#       also add node_list and poi_list to zone dictionary\n",
    "updated_dict = gd.sync_geometry_between_zone_and_node_poi(zone_dict, node_dict, poi_dict)\n",
    "\n",
    "zone_dict_update, node_dict_update, poi_dict_update = updated_dict.values()\n",
    "\n",
    "# Generate poi trip rate for each poi\n",
    "\n",
    "poi_trip_rate = gd.gen_poi_trip_rate(poi_dict_update, trip_rate_file=\"\", trip_purpose=1)\n",
    "\n",
    "# Generate node production attraction for each node based on poi_trip_rate\n",
    "\n",
    "node_prod_attr = gd.gen_node_prod_attr(node_dict_update, poi_trip_rate)\n",
    "\n",
    "# Calculate zone production and attraction based on node production and attraction\n",
    "\n",
    "zone_prod_attr = gd.calc_zone_prod_attr(node_prod_attr, zone_dict_update)\n",
    "\n",
    "# Calculate zone-to-zone od distance matrix\n",
    "\n",
    "zone_od_distance_matrix = gd.calc_zone_od_distance_matrix(zone_dict_update)\n",
    "\n",
    "# Run gravity model to generate agent-based demand\n",
    "\n",
    "df_demand = gd.run_gravity_model(zone_prod_attr, zone_od_distance_matrix)\n",
    "# generate agent-based demand\n",
    "df_agent = gd.gen_agent_based_demand(node_prod_attr, zone_prod_attr, df_demand=df_demand)\n",
    "\n",
    "print(gd.pkg_settings)\n",
    "\n",
    "# Output demand, agent, zone, zone_od_dist_table, zone_od_dist_matrix files\n",
    "gd.save_demand\n",
    "gd.save_agent\n",
    "gd.save_zone\n",
    "gd.save_zone_od_dist_table\n",
    "gd.save_zone_od_dist_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3dee08-843d-4a89-b87c-d614d27c6912",
   "metadata": {},
   "source": [
    "#### Finding the closest node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "736eca9d-903b-4eec-8833-0301264ea623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest node is now located in the folder\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate haversine distance\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    r = 6371  # Radius of Earth in kilometers\n",
    "    return c * r\n",
    "\n",
    "# Load the zone and node CSVs into dataframes\n",
    "zones_df = pd.read_csv('./data/1m/zone.csv', converters={'node_id_list': literal_eval}, low_memory=False )\n",
    "nodes_df = pd.read_csv('./data/1m/node.csv',low_memory=False)\n",
    "\n",
    "# Function to find the closest node ID to the zone's centroid where the node is a POI\n",
    "def find_closest_node_id(node_id_list, centroid_x, centroid_y):\n",
    "    min_distance = float('inf')\n",
    "    closest_node_id = None\n",
    "    poi_nodes_df = nodes_df[nodes_df['activity_type'] == 'poi']  # Filter nodes for POIs only\n",
    "    for node_id in node_id_list:\n",
    "        node = poi_nodes_df[poi_nodes_df['node_id'] == node_id]\n",
    "        if not node.empty:\n",
    "            distance = haversine(centroid_x, centroid_y, node.iloc[0]['x_coord'], node.iloc[0]['y_coord'])\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                closest_node_id = node_id\n",
    "    return closest_node_id\n",
    "\n",
    "# Add a new column for the closest node ID to each zone where production > 0\n",
    "zones_df['closest_node_id'] = zones_df.apply(\n",
    "    lambda row: find_closest_node_id(row['node_id_list'], row['centroid_x'], row['centroid_y']) if row['production'] > 0 else None, axis=1)\n",
    "\n",
    "# Output the zones dataframe with the closest node ID\n",
    "zones_df.to_csv('./data/1m/updated_zones_with_closest_node.csv', index=False)\n",
    "\n",
    "centroid_nodes_df = nodes_df[nodes_df['node_id'].isin(zones_df['closest_node_id'])]\n",
    "\n",
    "# Export this filtered DataFrame to a new CSV file\n",
    "centroid_nodes_df.to_csv('./data/1m/centroid_nodes.csv', index=False)\n",
    "\n",
    "print( \"Closest node is now located in the folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05836ba5-39f6-4006-a2a4-259f5eefaa67",
   "metadata": {},
   "source": [
    "#### Strip the Unsused POI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfb95966-2856-42e9-96a8-6a91f5fdac81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used POI and Connector are now stripped out\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV files\n",
    "nodes = pd.read_csv('./data/1m/node.csv', low_memory=False)\n",
    "links = pd.read_csv('./data/1m/link.csv', low_memory=False)\n",
    "centroid_nodes = pd.read_csv('./data/0.2m/centroid_nodes.csv')\n",
    "\n",
    "# Convert node_id in centroid_nodes to a set for fast lookup\n",
    "centroid_node_ids = set(centroid_nodes['node_id'])\n",
    "\n",
    "# Filter nodes to keep\n",
    "nodes_filtered = nodes[(nodes['node_id'].isin(centroid_node_ids)) | (nodes['activity_type'] != 'poi')]\n",
    "\n",
    "nodes_filtered.to_csv('./data/1m/node.csv', index=False)\n",
    "\n",
    "# Update the set of valid node_ids from the filtered nodes\n",
    "valid_node_ids = set(nodes_filtered['node_id'])\n",
    "\n",
    "# Filter links to keep\n",
    "links_filtered = links[(links['from_node_id'].isin(valid_node_ids)) & (links['to_node_id'].isin(valid_node_ids))]\n",
    "\n",
    "links_filtered.to_csv('./data/1m/link.csv', index=False)\n",
    "\n",
    "print( \"Used POI and Connector are now stripped out\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbb65da-444b-49fd-8525-9cd895fab9c2",
   "metadata": {},
   "source": [
    "#### Relabelling nodes and links prioritizing closest node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f518913-bcd9-49d6-a92c-12126aae3c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link and Nodes have been repriotized\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the CSV files into pandas DataFrames\n",
    "node_df = pd.read_csv('./data/1m/node.csv',  low_memory=False)\n",
    "link_df = pd.read_csv('./data/1m/link.csv',  low_memory=False)\n",
    "zone_df = pd.read_csv('./data/1m/updated_zones_with_closest_node.csv', low_memory=False)\n",
    "\n",
    "# Exclude null values and identify closest nodes\n",
    "closest_nodes = zone_df['closest_node_id'].dropna().unique()\n",
    "\n",
    "# Ensure all nodes are sorted to maintain a predictable order after prioritizing closest nodes\n",
    "all_nodes_sorted = sorted(node_df['node_id'].unique())\n",
    "\n",
    "# New ordering: closest nodes first, followed by the rest, excluding already prioritized ones\n",
    "new_ordered_nodes = list(closest_nodes) + [node for node in all_nodes_sorted if node not in closest_nodes]\n",
    "\n",
    "# Create a mapping of old node IDs to new sequential IDs, starting from 1\n",
    "new_node_mapping = {old_id: new_id for new_id, old_id in enumerate(new_ordered_nodes, start=1)}\n",
    "\n",
    "# Apply the new labeling\n",
    "node_df['actual_node_id'] = node_df['node_id'].map(new_node_mapping)\n",
    "link_df['fromID'] = link_df['from_node_id'].map(new_node_mapping)\n",
    "link_df['toID'] = link_df['to_node_id'].map(new_node_mapping)\n",
    "\n",
    "# Save the updated DataFrames (optional)\n",
    "node_df.to_csv('./data/1m/node.csv', index=False)\n",
    "link_df.to_csv('./data/1m/link.csv', index=False)\n",
    "\n",
    "print( \"Link and Nodes have been repriotized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da78c2ff-1ad4-4a0d-a6fd-9bcc7dae08f6",
   "metadata": {},
   "source": [
    "#### Relabelling the demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "049be1bf-601f-420d-b581-755a47c59f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The demand has been relabeled\n"
     ]
    }
   ],
   "source": [
    "# Load the data from a CSV file\n",
    "df = pd.read_csv('./data/1m/demand.csv')\n",
    "\n",
    "# Creating a unique and sorted list of o_zone_id values\n",
    "sorted_unique_o_zones = sorted(pd.unique(df['d_zone_id']))\n",
    "mapping = {old_id: new_id for new_id, old_id in enumerate(sorted_unique_o_zones, start=1)}\n",
    "\n",
    "# Apply the mapping to create new columns for o_zone_id and d_zone_id\n",
    "df['o_zone_new_id'] = df['o_zone_id'].map(mapping)\n",
    "df['d_zone_new_id'] = df['d_zone_id'].map(mapping)\n",
    "\n",
    "# Save the modified DataFrame back to a new CSV file if needed\n",
    "# Change 'yourpath' to a directory you have access to\n",
    "df.to_csv('./data/1m/demand_modified.csv', index=False)\n",
    "\n",
    "print( \"The demand has been relabeled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6448993-90a2-4b1e-ba7a-9c2775d7a2d0",
   "metadata": {},
   "source": [
    "#### Calculating the capacity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e799f1b2-b8f2-4e11-995d-6f7e0f4db12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Capacity have been calculated. Move to the next file to generate the tntp file\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./data/1m/link.csv', low_memory=False)\n",
    "\n",
    "# Only perform the operation where the road type is not 'poi'\n",
    "data.loc[data['Road Type'] != 'poi', 'capacity'] = data['capacity'] * data['Number of Lanes']\n",
    "data.loc[data['Road Type'] == 'connector', 'capacity'] = 9999\n",
    "data.to_csv('./data/1m/link.csv', index=False)\n",
    "\n",
    "print( \"The Capacity have been calculated. Move to the next file to generate the tntp file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c14a28-2fa9-4d99-925f-a9ae87301553",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
